{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy, get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data.utils import TARGET_COL, INTERIM_DIR, MODELS_DIR, get_cat_var_distribution, compute_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CHECKPOINT = \"camembert/camembert-large\"\n",
    "\n",
    "\n",
    "RANDOM_SEED = 0  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "logging.info(f\"{RANDOM_SEED=}\")\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "TASK_NAME = \"hasrelation\"\n",
    "logging.info(f\"{TASK_NAME=}\")\n",
    "STEP1_TASK_TARGET_COL = f\"{TASK_NAME}_label\"\n",
    "logging.info(f\"{STEP1_TASK_TARGET_COL=}\")\n",
    "TASK_INPUT_COL = \"input_text\"\n",
    "\n",
    "FOLD_NUM = 1\n",
    "logging.info(f\"{FOLD_NUM=}\")\n",
    "\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "\n",
    "USED_COLUMNS = [\"text_index\", \"e1_id\", \"e2_id\", \"e1_type\", \"e2_type\", TARGET_COL, TASK_INPUT_COL, STEP1_TASK_TARGET_COL]\n",
    "logging.info(f\"{USED_COLUMNS=}\")\n",
    "\n",
    "model_checkpoints_dir = os.path.join(MODELS_DIR, f\"mth2-{TASK_NAME}-fold{FOLD_NUM}-{BASE_CHECKPOINT.split('/')[-1]}-uncased\")\n",
    "logging.info(f\"{model_checkpoints_dir=}\")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprossed_data(parquet_path: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(parquet_path, columns=USED_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_preprossed_data(f\"data/defi-text-mine-2025/interim/train-fold{FOLD_NUM}-mth2.parquet\")\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = load_preprossed_data(f\"data/defi-text-mine-2025/interim/validation-fold{FOLD_NUM}-mth2.parquet\")\n",
    "val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cat_var_distribution(train_df[STEP1_TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cat_var_distribution(val_df[STEP1_TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[TASK_INPUT_COL], truncation=True, max_length=300) # max n_token without loosing entity, see setp0_data_preparation\n",
    "tokenized_datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df, preserve_index=False).shuffle(seed=RANDOM_SEED),\n",
    "    \"validation\": Dataset.from_pandas(val_df, preserve_index=False)\n",
    "}).map(lambda x: {TASK_INPUT_COL: x[TASK_INPUT_COL].lower()}).map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"validation\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init the data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cat_var_distribution(train_df[STEP1_TASK_TARGET_COL])[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cat_var_distribution(train_df[STEP1_TASK_TARGET_COL]).reset_index(drop=False)[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = train_df.shape[0]\n",
    "n_classes = train_df[STEP1_TASK_TARGET_COL].nunique()\n",
    "# def compute_class_weights2(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "#     return get_cat_var_distribution(lbl_df[STEP1_TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "# class_weights_df = compute_class_weights2(train_df)\n",
    "class_weights_df = compute_class_weights(train_df, label_columns=[STEP1_TASK_TARGET_COL])\n",
    "pd.concat([get_cat_var_distribution(train_df[STEP1_TASK_TARGET_COL]), class_weights_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights_df.values.tolist()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train_df[STEP1_TASK_TARGET_COL].nunique()\n",
    "print(f\"{n_classes=}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer and launch the training\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "MAX_EPOCHS = 50\n",
    "TRAIN_BATCH_SIZE=8\n",
    "VAL_BATCH_SIZE=8\n",
    "LEARNING_RATE = 1e-6\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_checkpoints_dir,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,    \n",
    "    per_device_eval_batch_size=VAL_BATCH_SIZE,\n",
    "    num_train_epochs=MAX_EPOCHS,\n",
    "    eval_strategy=IntervalStrategy.STEPS, # steps\n",
    "    eval_steps = 3000, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    save_steps=3000,\n",
    "    save_total_limit=1, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    # label_names=[STEP1_TASK_TARGET_COL],\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"customize the loss to leverage class weights\"\"\"\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.RAdam(\n",
    "#         model.parameters(),\n",
    "#         lr=LEARNING_RATE,\n",
    "#         betas=(0.9, 0.999),\n",
    "#         eps=1e-8,\n",
    "#         weight_decay=WEIGHT_DECAY,\n",
    "#     )\n",
    "# total_steps = int(tokenized_datasets[\"train\"].num_rows/TRAIN_BATCH_SIZE) * training_args.num_train_epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=int(0.1 * total_steps),\n",
    "#     num_training_steps=total_steps\n",
    "# )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    # optimizers=(optimizer, scheduler),\n",
    "    train_dataset=tokenized_datasets[\"train\"].rename_column(STEP1_TASK_TARGET_COL, \"label\"),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].rename_column(STEP1_TASK_TARGET_COL, \"label\"),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(resume_from_checkpoint=trainer.state.best_model_checkpoint)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, access the path of the best checkpoint like this\n",
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "best_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_output = trainer.predict(tokenized_datasets[\"train\"], metric_key_prefix=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = torch.sigmoid(torch.from_numpy(train_pred_output.predictions)).argmax(axis=1).numpy()\n",
    "train_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y_true = val_pred_output.label_ids\n",
    "train_y_true = tokenized_datasets['train'][STEP1_TASK_TARGET_COL]\n",
    "print(train_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_output = trainer.predict(tokenized_datasets[\"validation\"], metric_key_prefix=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_pred = torch.sigmoid(torch.from_numpy(val_pred_output.predictions)).argmax(axis=1).numpy()\n",
    "val_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_y_true = val_pred_output.label_ids\n",
    "val_y_true = tokenized_datasets['validation'][STEP1_TASK_TARGET_COL]\n",
    "print(val_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_output.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=train_y_true, y_pred=train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=val_y_true, y_pred=val_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=val_y_true, y_pred=val_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=val_y_true, y_pred=val_y_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"validation\"].select_columns(USED_COLUMNS).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_true_vs_pred_df = pd.concat([pd.DataFrame({\"y_true\": val_y_true, \"y_pred\": val_y_pred}), tokenized_datasets[\"validation\"].select_columns(USED_COLUMNS).to_pandas()], axis=1)\n",
    "# val_y_true_vs_pred_df = pd.DataFrame({\"y_true\": val_y_true, \"y_pred\": val_y_pred})\n",
    "val_y_true_vs_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negative\n",
    "false_neg_df = val_y_true_vs_pred_df.query(\"y_true==1 & y_true != y_pred\")\n",
    "false_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_df[TARGET_COL].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_df.query(f\"\"\" {TARGET_COL}==\"['HAS_FOR_LENGTH']\" \"\"\")[TASK_INPUT_COL].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_df.query(f\"\"\" {TARGET_COL}==\"['HAS_FOR_LENGTH']\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = classifier = pipeline(\"text-classification\", model=best_ckpt_path, device=\"cuda\")\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Le { super-navire } { Thang Long }, mis en service le 6 mai dernier, a coulé avec à son bord plusieurs passagers. Le { bateau } à grande vitesse était un { engin } à simple coque et constituait le plus grand { navire } du pays. Il mesurait [ 77,46 mètres ] de long avec une capacité de 1017 passagers.'\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(text.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
