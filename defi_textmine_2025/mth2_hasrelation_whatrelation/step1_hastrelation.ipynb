{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04:44:49|INFO|config.py:58] PyTorch version 2.3.1 available.\n",
      "[04:44:49|INFO|config.py:105] TensorFlow version 2.16.2 available.\n",
      "2024-10-08 04:44:50.043515: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 04:44:50.051308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 04:44:50.062178: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 04:44:50.062199: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 04:44:50.069458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 04:44:50.639594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data.utils import TARGET_COL, INTERIM_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# BASE_CHECKPOINT = \"bert-base-uncased\"\n",
    "# BASE_CHECKPOINT = \"bert-base-multilingual-cased\"\n",
    "BASE_CHECKPOINT = \"camembert/camembert-base\"\n",
    "TASK_NAME = \"hasrelation\"\n",
    "TASK_TARGET_COL = \"label\" # hasrelation?\n",
    "TASK_INPUT_COL = \"input_text\"\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "\n",
    "generated_data_dir_path = os.path.join(INTERIM_DIR, \"reduced_text_w_entity_bracket\")\n",
    "assert os.path.exists(generated_data_dir_path)\n",
    "train_dir = os.path.join(generated_data_dir_path, \"train\")\n",
    "test_dir = os.path.join(generated_data_dir_path, \"test\")\n",
    "\n",
    "preprocessed_data_dir = os.path.join(INTERIM_DIR, \"one_hot_reduced_text_w_entity_bracket\")\n",
    "labeled_preprocessed_data_dir_path = os.path.join(preprocessed_data_dir,\"train\")\n",
    "! mkdir -p {labeled_preprocessed_data_dir_path}\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_var_distribution(cat_var: pd.Series) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [cat_var.value_counts(), cat_var.value_counts(normalize=True)], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets for the binary text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_index</th>\n",
       "      <th>e1_id</th>\n",
       "      <th>e2_id</th>\n",
       "      <th>e1_type</th>\n",
       "      <th>e2_type</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un { incendie } ...</td>\n",
       "      <td>FIRE | GATHERING | Au milieu de l’[ interview ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un [ incendie ] ...</td>\n",
       "      <td>GATHERING | FIRE | Au milieu de l’{ interview ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un incendie est ...</td>\n",
       "      <td>CBRN_EVENT | GATHERING | Au milieu de l’[ inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un incendie est ...</td>\n",
       "      <td>GATHERING | CBRN_EVENT | Au milieu de l’{ inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’interview, un [ incendie ] est ...</td>\n",
       "      <td>CBRN_EVENT | FIRE | Au milieu de l’interview, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122039</th>\n",
       "      <td>41884</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>MATERIEL | COLOR | Au moment de sortir de la p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122040</th>\n",
       "      <td>41884</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la { porte } du magasin...</td>\n",
       "      <td>MATERIEL | COLOR | Au moment de sortir de la {...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122041</th>\n",
       "      <td>41884</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depuis la { fenêtre } des toilettes, monsieur ...</td>\n",
       "      <td>MATERIEL | COLOR | Depuis la { fenêtre } des t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122042</th>\n",
       "      <td>41884</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>['HAS_COLOR']</td>\n",
       "      <td>Depuis la fenêtre des toilettes, monsieur Bace...</td>\n",
       "      <td>MATERIEL | COLOR | Depuis la fenêtre des toile...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122043</th>\n",
       "      <td>41884</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>MATERIEL | COLOR | Au moment de sortir de la p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122044 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_index  e1_id  e2_id     e1_type     e2_type  \\\n",
       "0             2576      1      0        FIRE   GATHERING   \n",
       "1             2576      0      1   GATHERING        FIRE   \n",
       "2             2576      2      0  CBRN_EVENT   GATHERING   \n",
       "3             2576      0      2   GATHERING  CBRN_EVENT   \n",
       "4             2576      2      1  CBRN_EVENT        FIRE   \n",
       "...            ...    ...    ...         ...         ...   \n",
       "122039       41884     11     22    MATERIEL       COLOR   \n",
       "122040       41884     12     22    MATERIEL       COLOR   \n",
       "122041       41884     15     22    MATERIEL       COLOR   \n",
       "122042       41884     17     22    MATERIEL       COLOR   \n",
       "122043       41884     19     22    MATERIEL       COLOR   \n",
       "\n",
       "                                                     text  \\\n",
       "0       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "1       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "2       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "3       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "4       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "...                                                   ...   \n",
       "122039  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122040  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122041  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122042  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122043  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "\n",
       "                  relations  \\\n",
       "0                       NaN   \n",
       "1       ['HAS_CONSEQUENCE']   \n",
       "2                       NaN   \n",
       "3       ['HAS_CONSEQUENCE']   \n",
       "4       ['HAS_CONSEQUENCE']   \n",
       "...                     ...   \n",
       "122039                  NaN   \n",
       "122040                  NaN   \n",
       "122041                  NaN   \n",
       "122042        ['HAS_COLOR']   \n",
       "122043                  NaN   \n",
       "\n",
       "                                             reduced_text  \\\n",
       "0       Au milieu de l’[ interview ], un { incendie } ...   \n",
       "1       Au milieu de l’{ interview }, un [ incendie ] ...   \n",
       "2       Au milieu de l’[ interview ], un incendie est ...   \n",
       "3       Au milieu de l’{ interview }, un incendie est ...   \n",
       "4       Au milieu de l’interview, un [ incendie ] est ...   \n",
       "...                                                   ...   \n",
       "122039  Au moment de sortir de la porte du magasin, Mo...   \n",
       "122040  Au moment de sortir de la { porte } du magasin...   \n",
       "122041  Depuis la { fenêtre } des toilettes, monsieur ...   \n",
       "122042  Depuis la fenêtre des toilettes, monsieur Bace...   \n",
       "122043  Au moment de sortir de la porte du magasin, Mo...   \n",
       "\n",
       "                                               input_text  label  \n",
       "0       FIRE | GATHERING | Au milieu de l’[ interview ...      0  \n",
       "1       GATHERING | FIRE | Au milieu de l’{ interview ...      1  \n",
       "2       CBRN_EVENT | GATHERING | Au milieu de l’[ inte...      0  \n",
       "3       GATHERING | CBRN_EVENT | Au milieu de l’{ inte...      1  \n",
       "4       CBRN_EVENT | FIRE | Au milieu de l’interview, ...      1  \n",
       "...                                                   ...    ...  \n",
       "122039  MATERIEL | COLOR | Au moment de sortir de la p...      0  \n",
       "122040  MATERIEL | COLOR | Au moment de sortir de la {...      0  \n",
       "122041  MATERIEL | COLOR | Depuis la { fenêtre } des t...      0  \n",
       "122042  MATERIEL | COLOR | Depuis la fenêtre des toile...      1  \n",
       "122043  MATERIEL | COLOR | Au moment de sortir de la p...      0  \n",
       "\n",
       "[122044 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv(dir_or_file_path: str, index_col=None, sep=',') -> pd.DataFrame:\n",
    "    if os.path.isdir(dir_or_file_path):\n",
    "        all_files = glob.glob(os.path.join(dir_or_file_path , \"*.csv\"))  \n",
    "    else:\n",
    "        assert dir_or_file_path.endswith(\".csv\")\n",
    "        all_files = [dir_or_file_path]\n",
    "    assert len(all_files) > 0\n",
    "    return pd.concat([pd.read_csv(filename, index_col=index_col, header=0, sep=sep) for filename in all_files], axis=0, ignore_index=True)\n",
    "\n",
    "train_df = load_csv(train_dir, index_col=0).assign(**{\n",
    "        TASK_INPUT_COL: lambda df: df[[\"e1_type\", \"e2_type\", \"reduced_text\"]].apply(lambda row: ' | '.join(row.values.astype(str)), axis=1),\n",
    "        TASK_TARGET_COL: lambda df: 2 + ~pd.isnull(df.relations).astype(int),\n",
    "    },\n",
    ")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95650</td>\n",
       "      <td>0.783734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26394</td>\n",
       "      <td>0.216266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      95650    0.783734\n",
       "1      26394    0.216266"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97635, 10), (24409, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_df, val_df = train_test_split(train_df, test_size=VALIDATION_RATE, shuffle=True, random_state=RANDOM_SEED, stratify=train_df[TASK_TARGET_COL])\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76520</td>\n",
       "      <td>0.783735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.216265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      76520    0.783735\n",
       "1      21115    0.216265"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19130</td>\n",
       "      <td>0.783727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5279</td>\n",
       "      <td>0.216273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      19130    0.783727\n",
       "1       5279    0.216273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(val_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21115, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_train_df = train_df.query(f\"{TASK_TARGET_COL}==1\")\n",
    "positive_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76520, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_train_df = train_df.query(f\"{TASK_TARGET_COL}==0\")\n",
    "negative_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42230, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes\n",
    "train_df = pd.concat([positive_train_df, negative_train_df.sample(positive_train_df.shape[0])], axis=0)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "# task_special_tokens = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] + [\n",
    "#     f\"<{entity_class}>\" for entity_class in entity_classes\n",
    "# ]\n",
    "# # add special tokens to the tokenizer\n",
    "# num_added_tokens = tokenizer.add_tokens(task_special_tokens, special_tokens=True)\n",
    "# num_added_tokens, len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "task_datasets = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 1109,\n",
       " 'e1_id': 7,\n",
       " 'e2_id': 2,\n",
       " 'e1_type': 'CIVILIAN',\n",
       " 'e2_type': 'PLACE',\n",
       " 'text': 'Une voiture bleue a percuté un { piéton } à Charly-sur-Marne vendredi soir. D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ]. La représentante du respect des droits de l’homme, Madame Rodríguez Annie-Christine, a lancé un avis de recherche à la télévision afin de retrouver le conducteur. Des affiches et des tracts ont été distribués dans la ville en plus des annonces diffusées à la radio. En effet, les caméras de surveillance des magasins situés aux alentours de l’accident ont filmé le visage des fugitifs. La { victime } a été transportée à l’hôpital. Son pronostic vital n’est pas engagé.',\n",
       " 'relations': \"['HAS_CONTROL_OVER', 'IS_LOCATED_IN']\",\n",
       " 'reduced_text': 'D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ].',\n",
       " 'input_text': 'CIVILIAN | PLACE | D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ].',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 41177,\n",
       " 'e1_id': 16,\n",
       " 'e2_id': 11,\n",
       " 'e1_type': 'GROUP_OF_INDIVIDUALS',\n",
       " 'e2_type': 'PLACE',\n",
       " 'text': 'Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Une école primaire catholique réservée aux jeunes filles a été bombardée par l\\'association terroriste \"Harmattan arabe\". Les écolières étaient en cours d\\'histoire au moment de l\\'attaque. Les malfrats ont ensuite enlevé les jeunes filles pour les contraindre à porter le voile et à étudier le Coran. Deux personnes ont été tuées suite aux boulets envoyés. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l\\'école catholique, ont été blessées. Transportées d\\'urgence à l\\'hôpital dans de vieilles ambulances, les blessés étaient entre la vie et la mort.',\n",
       " 'relations': \"['IS_LOCATED_IN']\",\n",
       " 'reduced_text': \"Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l'école catholique, ont été blessées.\",\n",
       " 'input_text': \"GROUP_OF_INDIVIDUALS | PLACE | Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l'école catholique, ont été blessées.\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c126550e55064b32badd28785b88a605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e54cd2c05c44c2a3854a33e3015908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[TASK_INPUT_COL], truncation=True)\n",
    "\n",
    "# We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately\n",
    "# This is way faster\n",
    "# Source https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n",
    "# columns are removed because DataCollatorWithPadding doesn't support any other columns than the ones produced by the tokenizer (or non tensors)\n",
    "tokenized_datasets = task_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text_index',\n",
       "  'e1_id',\n",
       "  'e2_id',\n",
       "  'e1_type',\n",
       "  'e2_type',\n",
       "  'text',\n",
       "  'relations',\n",
       "  'reduced_text',\n",
       "  'input_text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'attention_mask'],\n",
       " 'validation': ['text_index',\n",
       "  'e1_id',\n",
       "  'e2_id',\n",
       "  'e1_type',\n",
       "  'e2_type',\n",
       "  'text',\n",
       "  'relations',\n",
       "  'reduced_text',\n",
       "  'input_text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'attention_mask']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_datasets[\"train\"][1]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token numbers distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d31c593ae14fc3aab68d5bddbaa5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510d15a1c9484a50b5439649b294ea03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "\n",
    "def count_token_in_dataset_element(example: Dict[str, Any]) -> Dict[str, int]:\n",
    "    return {\"n_tokens\": count_tokens(example[TASK_INPUT_COL])}\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(count_token_in_dataset_element)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 42230/42230 [00:03<00:00, 12259.99it/s]\n",
      "validation: 100%|██████████| 24409/24409 [00:02<00:00, 12126.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42230.000000</td>\n",
       "      <td>24409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.639758</td>\n",
       "      <td>79.756442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.986018</td>\n",
       "      <td>30.651928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train    validation\n",
       "count  42230.000000  24409.000000\n",
       "mean      77.639758     79.756442\n",
       "std       31.986018     30.651928\n",
       "min       19.000000     18.000000\n",
       "25%       55.000000     58.000000\n",
       "50%       71.000000     75.000000\n",
       "75%       93.000000     95.000000\n",
       "max      311.000000    284.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2ntokens_df = pd.DataFrame(\n",
    "    {\n",
    "        split_name: pd.Series(\n",
    "            [e[\"n_tokens\"] for e in tqdm(tokenized_datasets[split_name], split_name)],\n",
    "            name=f\"{split_name}_text_n_tokens\",\n",
    "        )\n",
    "        for split_name in tokenized_datasets.keys()\n",
    "    }\n",
    ")\n",
    "split2ntokens_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40c1286e76d4a8ea1355fe05e8c217c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "    num_rows: 145\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440e4697038b4328948592edaf4cf668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'PLACE | PLACE | Le < bâtiment > a été évacué et aéré.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] == 19)[0]['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227fa9082f6a492d9675256438628693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"CIVILIAN | PLACE | Le 23 mai 2017, l'association protégeant les droits des enfants a décidé de construire un [ terrain de basket ] pour les jeunes de Marrakech. Cependant, deux ans après la construction du [ terrain ], les habitants ont commencé à avoir des différends concernant sa gestion. Le maire de la ville, Monsieur Kireg Mohamed, a expliqué que les habitants du quartier Est, zone où se trouve le [ terrain ], ne laissaient pas les habitants du quartier Ouest [ l' ]utiliser. D'après certains jeunes du quartier Est, cette opposition est due au fait que ceux du quartier Ouest salissent le [ terrain ] et n'utilisent pas les poubelles disposées dans la zone. Jeudi dernier, l'inévitable s'est produit et a entraîné l'envoi à l'hôpital d'{ Hassan Mohamed }, le { fils } du maire. D'après des sources anonymes, des jeunes du quartier Ouest sont entrés sur le [ terrain ] sans l'accord du gardien. Ce dernier a prévenu des gens qui se trouvaient là, qui ont commencé à tabasser les quatre jeunes présents sur le [ terrain ]. Sans l'intervention de la gendarmerie, la confrontation a été sanglante, sans compter la destruction des biens comme les véhicules stationnés à côté du [ terrain ]. Au moment où nous écrivons, la colère des parents et amis de la { victime } est de plus en plus noire et cela peut entraîner de terribles confrontations.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 300)[0]['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the batch-level padding with a data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 62, 41, 39, 53, 38, 62, 43]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets.remove_columns(task_datasets[\"train\"].column_names)[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items()}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 62]),\n",
       " 'attention_mask': torch.Size([8, 62]),\n",
       " 'n_tokens': torch.Size([8])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  proportion  weight\n",
       "1  21115         0.5     1.0\n",
       "0  21115         0.5     1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = train_df.shape[0]\n",
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "def compute_class_weights(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "    return get_cat_var_distribution(lbl_df[TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "pd.concat([get_cat_var_distribution(train_df[TASK_TARGET_COL]), compute_class_weights(train_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 768, padding_idx=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "print(f\"{n_classes=}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=0)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-checkpoints\"),\n",
    "    per_device_train_batch_size=20,    \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=IntervalStrategy.EPOCH, # steps\n",
    "    # eval_steps = 50, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-tensorboard\"),\n",
    "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model = 'eval_loss',\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "[04:45:27|ERROR|jupyter.py:224] Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtagny\u001b[0m (\u001b[33mifiafrik-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tagny/github/relation_extraction_textmine25/wandb/run-20241008_044528-8s6ab12g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ifiafrik-team/huggingface/runs/8s6ab12g' target=\"_blank\">data/defi-text-mine-2025/models/hasrelation-byTrainerAPI-checkpoints</a></strong> to <a href='https://wandb.ai/ifiafrik-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ifiafrik-team/huggingface' target=\"_blank\">https://wandb.ai/ifiafrik-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ifiafrik-team/huggingface/runs/8s6ab12g' target=\"_blank\">https://wandb.ai/ifiafrik-team/huggingface/runs/8s6ab12g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10560' max='21120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10560/21120 47:29 < 47:29, 3.71 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.344476</td>\n",
       "      <td>0.845754</td>\n",
       "      <td>0.781541</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>0.805412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.331398</td>\n",
       "      <td>0.869024</td>\n",
       "      <td>0.804652</td>\n",
       "      <td>0.880574</td>\n",
       "      <td>0.829954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.343603</td>\n",
       "      <td>0.871318</td>\n",
       "      <td>0.808075</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>0.834259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.378443</td>\n",
       "      <td>0.876357</td>\n",
       "      <td>0.813547</td>\n",
       "      <td>0.893482</td>\n",
       "      <td>0.839972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152400</td>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.862059</td>\n",
       "      <td>0.799822</td>\n",
       "      <td>0.889435</td>\n",
       "      <td>0.825752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10560, training_loss=0.2505459835131963, metrics={'train_runtime': 2851.6084, 'train_samples_per_second': 148.092, 'train_steps_per_second': 7.406, 'total_flos': 1.66766261885796e+16, 'train_loss': 0.2505459835131963, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "TODO..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
