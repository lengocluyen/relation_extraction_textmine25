{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07:28:26|INFO|config.py:58] PyTorch version 2.3.1 available.\n",
      "[07:28:26|INFO|config.py:105] TensorFlow version 2.16.2 available.\n",
      "2024-10-08 07:28:27.052557: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 07:28:27.060060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 07:28:27.070886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 07:28:27.070904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 07:28:27.077998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 07:28:27.654464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data.utils import TARGET_COL, INTERIM_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# BASE_CHECKPOINT = \"bert-base-uncased\"\n",
    "# BASE_CHECKPOINT = \"bert-base-multilingual-cased\"\n",
    "BASE_CHECKPOINT = \"camembert/camembert-large\"\n",
    "TASK_NAME = \"hasrelation\"\n",
    "TASK_TARGET_COL = \"label\" # hasrelation?\n",
    "TASK_INPUT_COL = \"input_text\"\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "\n",
    "generated_data_dir_path = os.path.join(INTERIM_DIR, \"reduced_text_w_entity_bracket\")\n",
    "assert os.path.exists(generated_data_dir_path)\n",
    "train_dir = os.path.join(generated_data_dir_path, \"train\")\n",
    "test_dir = os.path.join(generated_data_dir_path, \"test\")\n",
    "\n",
    "preprocessed_data_dir = os.path.join(INTERIM_DIR, \"one_hot_reduced_text_w_entity_bracket\")\n",
    "labeled_preprocessed_data_dir_path = os.path.join(preprocessed_data_dir,\"train\")\n",
    "! mkdir -p {labeled_preprocessed_data_dir_path}\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_var_distribution(cat_var: pd.Series) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [cat_var.value_counts(), cat_var.value_counts(normalize=True)], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets for the binary text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_index</th>\n",
       "      <th>e1_id</th>\n",
       "      <th>e2_id</th>\n",
       "      <th>e1_type</th>\n",
       "      <th>e2_type</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un { incendie } ...</td>\n",
       "      <td>Au milieu de l’[ interview ], un { incendie } ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un [ incendie ] ...</td>\n",
       "      <td>Au milieu de l’{ interview }, un [ incendie ] ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un incendie est ...</td>\n",
       "      <td>Au milieu de l’[ interview ], un incendie est ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un incendie est ...</td>\n",
       "      <td>Au milieu de l’{ interview }, un incendie est ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’interview, un [ incendie ] est ...</td>\n",
       "      <td>Au milieu de l’interview, un [ incendie ] est ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122039</th>\n",
       "      <td>41884</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122040</th>\n",
       "      <td>41884</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la { porte } du magasin...</td>\n",
       "      <td>Au moment de sortir de la { porte } du magasin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122041</th>\n",
       "      <td>41884</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depuis la { fenêtre } des toilettes, monsieur ...</td>\n",
       "      <td>Depuis la { fenêtre } des toilettes, monsieur ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122042</th>\n",
       "      <td>41884</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>['HAS_COLOR']</td>\n",
       "      <td>Depuis la fenêtre des toilettes, monsieur Bace...</td>\n",
       "      <td>Depuis la fenêtre des toilettes, monsieur Bace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122043</th>\n",
       "      <td>41884</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122044 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_index  e1_id  e2_id     e1_type     e2_type  \\\n",
       "0             2576      1      0        FIRE   GATHERING   \n",
       "1             2576      0      1   GATHERING        FIRE   \n",
       "2             2576      2      0  CBRN_EVENT   GATHERING   \n",
       "3             2576      0      2   GATHERING  CBRN_EVENT   \n",
       "4             2576      2      1  CBRN_EVENT        FIRE   \n",
       "...            ...    ...    ...         ...         ...   \n",
       "122039       41884     11     22    MATERIEL       COLOR   \n",
       "122040       41884     12     22    MATERIEL       COLOR   \n",
       "122041       41884     15     22    MATERIEL       COLOR   \n",
       "122042       41884     17     22    MATERIEL       COLOR   \n",
       "122043       41884     19     22    MATERIEL       COLOR   \n",
       "\n",
       "                                                     text  \\\n",
       "0       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "1       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "2       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "3       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "4       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "...                                                   ...   \n",
       "122039  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122040  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122041  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122042  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122043  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "\n",
       "                  relations  \\\n",
       "0                       NaN   \n",
       "1       ['HAS_CONSEQUENCE']   \n",
       "2                       NaN   \n",
       "3       ['HAS_CONSEQUENCE']   \n",
       "4       ['HAS_CONSEQUENCE']   \n",
       "...                     ...   \n",
       "122039                  NaN   \n",
       "122040                  NaN   \n",
       "122041                  NaN   \n",
       "122042        ['HAS_COLOR']   \n",
       "122043                  NaN   \n",
       "\n",
       "                                             reduced_text  \\\n",
       "0       Au milieu de l’[ interview ], un { incendie } ...   \n",
       "1       Au milieu de l’{ interview }, un [ incendie ] ...   \n",
       "2       Au milieu de l’[ interview ], un incendie est ...   \n",
       "3       Au milieu de l’{ interview }, un incendie est ...   \n",
       "4       Au milieu de l’interview, un [ incendie ] est ...   \n",
       "...                                                   ...   \n",
       "122039  Au moment de sortir de la porte du magasin, Mo...   \n",
       "122040  Au moment de sortir de la { porte } du magasin...   \n",
       "122041  Depuis la { fenêtre } des toilettes, monsieur ...   \n",
       "122042  Depuis la fenêtre des toilettes, monsieur Bace...   \n",
       "122043  Au moment de sortir de la porte du magasin, Mo...   \n",
       "\n",
       "                                               input_text  label  \n",
       "0       Au milieu de l’[ interview ], un { incendie } ...      0  \n",
       "1       Au milieu de l’{ interview }, un [ incendie ] ...      1  \n",
       "2       Au milieu de l’[ interview ], un incendie est ...      0  \n",
       "3       Au milieu de l’{ interview }, un incendie est ...      1  \n",
       "4       Au milieu de l’interview, un [ incendie ] est ...      1  \n",
       "...                                                   ...    ...  \n",
       "122039  Au moment de sortir de la porte du magasin, Mo...      0  \n",
       "122040  Au moment de sortir de la { porte } du magasin...      0  \n",
       "122041  Depuis la { fenêtre } des toilettes, monsieur ...      0  \n",
       "122042  Depuis la fenêtre des toilettes, monsieur Bace...      1  \n",
       "122043  Au moment de sortir de la porte du magasin, Mo...      0  \n",
       "\n",
       "[122044 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv(dir_or_file_path: str, index_col=None, sep=',') -> pd.DataFrame:\n",
    "    if os.path.isdir(dir_or_file_path):\n",
    "        all_files = glob.glob(os.path.join(dir_or_file_path , \"*.csv\"))  \n",
    "    else:\n",
    "        assert dir_or_file_path.endswith(\".csv\")\n",
    "        all_files = [dir_or_file_path]\n",
    "    assert len(all_files) > 0\n",
    "    return pd.concat([pd.read_csv(filename, index_col=index_col, header=0, sep=sep) for filename in all_files], axis=0, ignore_index=True)\n",
    "\n",
    "train_df = load_csv(train_dir, index_col=0).assign(**{\n",
    "        # TASK_INPUT_COL: lambda df: df[[\"e1_type\", \"e2_type\", \"reduced_text\"]].apply(lambda row: ' | '.join(row.values.astype(str)), axis=1),\n",
    "        TASK_INPUT_COL: lambda df: df[\"reduced_text\"],\n",
    "        TASK_TARGET_COL: lambda df: 2 + ~pd.isnull(df.relations).astype(int),\n",
    "    },\n",
    ")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(INTERIM_DIR, \"train-reduced_text_w_entity_bracket.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(os.path.join(INTERIM_DIR, \"train-reduced_text_w_entity_bracket.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95650</td>\n",
       "      <td>0.783734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26394</td>\n",
       "      <td>0.216266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      95650    0.783734\n",
       "1      26394    0.216266"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97635, 10), (24409, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_df, val_df = train_test_split(train_df, test_size=VALIDATION_RATE, shuffle=True, random_state=RANDOM_SEED, stratify=train_df[TASK_TARGET_COL])\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76520</td>\n",
       "      <td>0.783735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.216265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      76520    0.783735\n",
       "1      21115    0.216265"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19130</td>\n",
       "      <td>0.783727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5279</td>\n",
       "      <td>0.216273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      19130    0.783727\n",
       "1       5279    0.216273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(val_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21115, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_train_df = train_df.query(f\"{TASK_TARGET_COL}==1\")\n",
    "positive_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76520, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_train_df = train_df.query(f\"{TASK_TARGET_COL}==0\")\n",
    "negative_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42230, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes\n",
    "train_df = pd.concat([positive_train_df, negative_train_df.sample(positive_train_df.shape[0])], axis=0)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 32063)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "task_special_tokens = [\"<\", \">\", \"{\", \"}\"] + [\n",
    "    f\"{entity_class}\" for entity_class in entity_classes\n",
    "]\n",
    "# add special tokens to the tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(task_special_tokens, special_tokens=True)\n",
    "num_added_tokens, len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "task_datasets = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 1109,\n",
       " 'e1_id': 7,\n",
       " 'e2_id': 2,\n",
       " 'e1_type': 'CIVILIAN',\n",
       " 'e2_type': 'PLACE',\n",
       " 'text': 'Une voiture bleue a percuté un { piéton } à Charly-sur-Marne vendredi soir. D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ]. La représentante du respect des droits de l’homme, Madame Rodríguez Annie-Christine, a lancé un avis de recherche à la télévision afin de retrouver le conducteur. Des affiches et des tracts ont été distribués dans la ville en plus des annonces diffusées à la radio. En effet, les caméras de surveillance des magasins situés aux alentours de l’accident ont filmé le visage des fugitifs. La { victime } a été transportée à l’hôpital. Son pronostic vital n’est pas engagé.',\n",
       " 'relations': \"['HAS_CONTROL_OVER', 'IS_LOCATED_IN']\",\n",
       " 'reduced_text': 'D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ].',\n",
       " 'input_text': 'D’après les témoins, le conducteur était en état d’ivresse et s’est enfui lorsqu’il a vu la { victime } au sol inerte, sur le [ trottoir ].',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 41177,\n",
       " 'e1_id': 16,\n",
       " 'e2_id': 11,\n",
       " 'e1_type': 'GROUP_OF_INDIVIDUALS',\n",
       " 'e2_type': 'PLACE',\n",
       " 'text': 'Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Une école primaire catholique réservée aux jeunes filles a été bombardée par l\\'association terroriste \"Harmattan arabe\". Les écolières étaient en cours d\\'histoire au moment de l\\'attaque. Les malfrats ont ensuite enlevé les jeunes filles pour les contraindre à porter le voile et à étudier le Coran. Deux personnes ont été tuées suite aux boulets envoyés. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l\\'école catholique, ont été blessées. Transportées d\\'urgence à l\\'hôpital dans de vieilles ambulances, les blessés étaient entre la vie et la mort.',\n",
       " 'relations': \"['IS_LOCATED_IN']\",\n",
       " 'reduced_text': \"Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l'école catholique, ont été blessées.\",\n",
       " 'input_text': \"Un drame est survenu ce matin dans un [ petit village ] du Nigeria. Vingt-trois { personnes }, dont Soumiya Duverney, le fondateur de l'école catholique, ont été blessées.\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9ebe51536544c6a930415e5167c569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738f63f64b87486eb765141a1c062324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[TASK_INPUT_COL], truncation=True)\n",
    "\n",
    "# We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately\n",
    "# This is way faster\n",
    "# Source https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n",
    "# columns are removed because DataCollatorWithPadding doesn't support any other columns than the ones produced by the tokenizer (or non tensors)\n",
    "tokenized_datasets = task_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text_index',\n",
       "  'e1_id',\n",
       "  'e2_id',\n",
       "  'e1_type',\n",
       "  'e2_type',\n",
       "  'text',\n",
       "  'relations',\n",
       "  'reduced_text',\n",
       "  'input_text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'attention_mask'],\n",
       " 'validation': ['text_index',\n",
       "  'e1_id',\n",
       "  'e2_id',\n",
       "  'e1_type',\n",
       "  'e2_type',\n",
       "  'text',\n",
       "  'relations',\n",
       "  'reduced_text',\n",
       "  'input_text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'attention_mask']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_datasets[\"train\"][1]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token numbers distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937b9870e7a04d8ba46ce8e33a284d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8e3921a9b9407097c2b2e827148a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "\n",
    "def count_token_in_dataset_element(example: Dict[str, Any]) -> Dict[str, int]:\n",
    "    return {\"n_tokens\": count_tokens(example[TASK_INPUT_COL])}\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(count_token_in_dataset_element)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 42230/42230 [00:03<00:00, 12373.98it/s]\n",
      "validation: 100%|██████████| 24409/24409 [00:01<00:00, 12389.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42230.000000</td>\n",
       "      <td>24409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.188894</td>\n",
       "      <td>63.261502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.646281</td>\n",
       "      <td>29.189710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train    validation\n",
       "count  42230.000000  24409.000000\n",
       "mean      61.188894     63.261502\n",
       "std       30.646281     29.189710\n",
       "min       11.000000     11.000000\n",
       "25%       39.000000     42.000000\n",
       "50%       54.000000     58.000000\n",
       "75%       76.000000     78.000000\n",
       "max      299.000000    266.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2ntokens_df = pd.DataFrame(\n",
    "    {\n",
    "        split_name: pd.Series(\n",
    "            [e[\"n_tokens\"] for e in tqdm(tokenized_datasets[split_name], split_name)],\n",
    "            name=f\"{split_name}_text_n_tokens\",\n",
    "        )\n",
    "        for split_name in tokenized_datasets.keys()\n",
    "    }\n",
    ")\n",
    "split2ntokens_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split2ntokens_df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1779a05f646a4cc9a93cf58fb218836a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5bd4828f8643ef8c04c4890b2e27b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/42230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'[ Toutes ] les { personnes présentes } sont ressorties saines et sauves.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] == 19)[0]['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 300)[0]['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the batch-level padding with a data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 46, 31, 28, 20, 20, 35, 34]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets.remove_columns(task_datasets[\"train\"].column_names)[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items()}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 42230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 46]),\n",
       " 'attention_mask': torch.Size([8, 46]),\n",
       " 'n_tokens': torch.Size([8])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  proportion  weight\n",
       "1  21115         0.5     1.0\n",
       "0  21115         0.5     1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = train_df.shape[0]\n",
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "def compute_class_weights(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "    return get_cat_var_distribution(lbl_df[TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "pd.concat([get_cat_var_distribution(train_df[TASK_TARGET_COL]), compute_class_weights(train_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32063, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "print(f\"{n_classes=}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32063, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-checkpoints\"),\n",
    "    per_device_train_batch_size=20,    \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=IntervalStrategy.EPOCH, # steps\n",
    "    # eval_steps = 50, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-tensorboard\"),\n",
    "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model = 'eval_loss',\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2387' max='21120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2387/21120 48:11 < 6:18:31, 0.82 it/s, Epoch 1.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.294774</td>\n",
       "      <td>0.874145</td>\n",
       "      <td>0.809645</td>\n",
       "      <td>0.876846</td>\n",
       "      <td>0.833775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/trainer.py:3518\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3516\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/accelerate/accelerator.py:2196\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2196\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, access the path of the best checkpoint like this\n",
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "best_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=best_ckpt_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"input_text\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.iloc[:10][[\"input_text\", \"label\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"text\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[TASK_TARGET_COL].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['input_ids'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
