{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data import TARGET_COL, INTERIM_DIR, MODELS_DIR, submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# BASE_CHECKPOINT = \"bert-base-uncased\"\n",
    "BASE_CHECKPOINT = \"bert-base-multilingual-cased\"\n",
    "# BASE_CHECKPOINT = \"camembert/camembert-base\"\n",
    "TASK_NAME = \"hasrelation_btc\"\n",
    "TASK_TARGET_COL = \"label\" # hasrelation?\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "\n",
    "generated_data_dir_path = os.path.join(INTERIM_DIR, \"multilabel_tagged_text_dataset\")\n",
    "assert os.path.exists(generated_data_dir_path)\n",
    "train_dir = os.path.join(generated_data_dir_path, \"train\")\n",
    "test_dir = os.path.join(generated_data_dir_path, \"test\")\n",
    "\n",
    "preprocessed_data_dir = os.path.join(INTERIM_DIR, \"one_hot_multilabel_tagged_text_dataset\")\n",
    "labeled_preprocessed_data_dir_path = os.path.join(preprocessed_data_dir,\"train\")\n",
    "! mkdir -p {labeled_preprocessed_data_dir_path}\n",
    "\n",
    "model_dir_path = os.path.join(MODELS_DIR, f\"finetuned-{BASE_CHECKPOINT}\")\n",
    "! mkdir -p {model_dir_path}\n",
    "model_dict_state_path = os.path.join(model_dir_path,\"MLTC_model_state.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_var_distribution(cat_var: pd.Series) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [cat_var.value_counts(), cat_var.value_counts(normalize=True)], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets for the binary text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_index</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124000</th>\n",
       "      <td>41884</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124001</th>\n",
       "      <td>41884</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124002</th>\n",
       "      <td>41884</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124003</th>\n",
       "      <td>41884</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124004</th>\n",
       "      <td>41884</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124005 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_index  e1  e2                                               text  \\\n",
       "0             2576   0   0  Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "1             2576   1   0  Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "2             2576   0   1  Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "3             2576   1   1  Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "4             2576   2   0  Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "...            ...  ..  ..                                                ...   \n",
       "124000       41884  11  22  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "124001       41884  12  22  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "124002       41884  15  22  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "124003       41884  17  22  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "124004       41884  19  22  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "\n",
       "        label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "124000      0  \n",
       "124001      0  \n",
       "124002      0  \n",
       "124003      1  \n",
       "124004      0  \n",
       "\n",
       "[124005 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv(dir_or_file_path: str, index_col=None, sep=',') -> pd.DataFrame:\n",
    "    if os.path.isdir(dir_or_file_path):\n",
    "        all_files = glob.glob(os.path.join(dir_or_file_path , \"*.csv\"))  \n",
    "    else:\n",
    "        assert dir_or_file_path.endswith(\".csv\")\n",
    "        all_files = [dir_or_file_path]\n",
    "    assert len(all_files) > 0\n",
    "    return pd.concat([pd.read_csv(filename, index_col=index_col, header=0, sep=sep) for filename in all_files], axis=0, ignore_index=True)\n",
    "\n",
    "labeled_df = load_csv(train_dir).assign(**{TASK_TARGET_COL: lambda df: 2 + ~pd.isnull(df.relations).astype(int)}).drop(TARGET_COL, axis=1)\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97611</td>\n",
       "      <td>0.787154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26394</td>\n",
       "      <td>0.212846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      97611    0.787154\n",
       "1      26394    0.212846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(labeled_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99204, 5), (24801, 5))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_df, val_df = train_test_split(labeled_df, test_size=VALIDATION_RATE, shuffle=True, random_state=RANDOM_SEED, stratify=labeled_df[TASK_TARGET_COL])\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78089</td>\n",
       "      <td>0.787156</td>\n",
       "      <td>0.793998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.212844</td>\n",
       "      <td>2.936420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  proportion    weight\n",
       "0  78089    0.787156  0.793998\n",
       "1  21115    0.212844  2.936420"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([get_cat_var_distribution(train_df[TASK_TARGET_COL]), compute_class_weights(train_df)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19522</td>\n",
       "      <td>0.787146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5279</td>\n",
       "      <td>0.212854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      19522    0.787146\n",
       "1       5279    0.212854"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(val_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59, 119606)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "task_special_tokens = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] + [\n",
    "    f\"<{entity_class}>\" for entity_class in entity_classes\n",
    "]\n",
    "# add special tokens to the tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(task_special_tokens, special_tokens=True)\n",
    "num_added_tokens, len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1', 'e2', 'text', 'label'],\n",
       "        num_rows: 99204\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1', 'e2', 'text', 'label'],\n",
       "        num_rows: 99204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "task_datasets = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 51469,\n",
       " 'e1': 14,\n",
       " 'e2': 6,\n",
       " 'text': 'La présence à forte dose d’une substance toxique a été retrouvée dans un stock de raisins blancs destinés à la fabrication de vin dans le <e1><PLACE>sud</e1> de l’Italie. Selon l’œnologue M. Djael Rodriguez, ce fait est de plus en plus courant dans l’univers viticole de cette <e1><PLACE>partie</e1> du pays où pourtant, aucune <e2><MATERIEL>substance chimique toxique</e2> n’est introduite dans le sol. C’est la preuve pour lui que tout est lié, et qu’il faudrait que le Ministère de l’Eau et de l’Assainissement assainisse le réseau hydraulique du pays dans son ensemble. Une telle mesure évitera, à l’avenir, que toute une récolte ne soit détruite à l’incinérateur, ce qui constitue un important manque à gagner pour les propriétaires de vignobles, souvent endettés à cause du fort coût des équipements et des frais fonciers.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 51407,\n",
       " 'e1': 0,\n",
       " 'e2': 18,\n",
       " 'text': \"Le <e2><TIME_EXACT>12 mai 2016</e2>, un <e1><NATURAL_EVENT>tremblement de terre</e1> a frappé de plein fouet l'Arizona. Plusieurs personnes ont dû quitter leur domicile grâce à des camions et des hélicoptères mis à disposition par le gouvernement. Le <e1><NATURAL_EVENT>sinistre</e1> a provoqué la destruction de plusieurs bâtiments, dont des hôpitaux. Plusieurs patients ont dû être évacués en urgence. Parmi eux, il y avait Madame Belkiss Miller, une femme de 21 ans qui avait donné naissance à un bébé prématuré dans une ambulance à l'entrée de la ville de Phoenix. Les pompiers se sont servis d'un brancard et de serviettes qu'ils avaient sous la main pour aider la patiente. La jeune femme et son fils s'en sont sortis sains et saufs. Les opérations de sauvetage ont continué dans tout l'État.\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea4adfca2a44279b8292e4ac5e5d7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a82f325fd994e05a5bcf2dbb4c529dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1', 'e2', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 99204\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1', 'e2', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 99204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "# We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately\n",
    "# This is way faster\n",
    "# Source https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n",
    "tokenized_datasets = task_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text_index',\n",
       "  'e1',\n",
       "  'e2',\n",
       "  'text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask'],\n",
       " 'validation': ['text_index',\n",
       "  'e1',\n",
       "  'e2',\n",
       "  'text',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the batch-level padding with a data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[209, 196, 233, 197, 192, 153, 166, 187]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns are removed because DataCollatorWithPadding doesn't support any other columns than the ones produced by the tokenizer (or non tensors)\n",
    "samples = tokenized_datasets.remove_columns(task_datasets[\"train\"].column_names)[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items()}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 233]),\n",
       " 'token_type_ids': torch.Size([8, 233]),\n",
       " 'attention_mask': torch.Size([8, 233])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97611</td>\n",
       "      <td>0.787154</td>\n",
       "      <td>0.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26394</td>\n",
       "      <td>0.212846</td>\n",
       "      <td>2.349113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  proportion    weight\n",
       "0  97611    0.787154  0.635200\n",
       "1  26394    0.212846  2.349113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = labeled_df.shape[0]\n",
    "n_classes = labeled_df[TASK_TARGET_COL].nunique()\n",
    "def compute_class_weights(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "    return get_cat_var_distribution(lbl_df[TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "pd.concat([get_cat_var_distribution(labeled_df[TASK_TARGET_COL]), compute_class_weights(labeled_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-trainer\"),\n",
    "    per_device_train_batch_size=16,    \n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    eval_strategy=IntervalStrategy.STEPS, # steps\n",
    "    eval_steps = 50, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-trainer-tensorboard\"),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
