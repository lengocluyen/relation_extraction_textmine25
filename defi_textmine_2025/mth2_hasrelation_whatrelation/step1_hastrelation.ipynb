{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:04:15|INFO|config.py:58] PyTorch version 2.3.1 available.\n",
      "[01:04:15|INFO|config.py:105] TensorFlow version 2.16.2 available.\n",
      "2024-10-09 01:04:16.086010: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 01:04:16.093977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 01:04:16.104987: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 01:04:16.105004: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 01:04:16.112393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 01:04:16.906721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data.utils import TARGET_COL, INTERIM_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# BASE_CHECKPOINT = \"bert-base-uncased\"\n",
    "# BASE_CHECKPOINT = \"bert-base-multilingual-cased\"\n",
    "BASE_CHECKPOINT = \"camembert/camembert-base\"\n",
    "TASK_NAME = \"hasrelation\"\n",
    "TASK_TARGET_COL = \"label\" # hasrelation?\n",
    "TASK_INPUT_COL = \"input_text\"\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "\n",
    "generated_data_dir_path = os.path.join(INTERIM_DIR, \"reduced_text_w_entity_bracket\")\n",
    "assert os.path.exists(generated_data_dir_path)\n",
    "train_dir = os.path.join(generated_data_dir_path, \"train\")\n",
    "test_dir = os.path.join(generated_data_dir_path, \"test\")\n",
    "\n",
    "preprocessed_data_dir = os.path.join(INTERIM_DIR, \"one_hot_reduced_text_w_entity_bracket\")\n",
    "labeled_preprocessed_data_dir_path = os.path.join(preprocessed_data_dir,\"train\")\n",
    "! mkdir -p {labeled_preprocessed_data_dir_path}\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_var_distribution(cat_var: pd.Series) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [cat_var.value_counts(), cat_var.value_counts(normalize=True)], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets for the binary text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_index</th>\n",
       "      <th>e1_id</th>\n",
       "      <th>e2_id</th>\n",
       "      <th>e1_type</th>\n",
       "      <th>e2_type</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un { incendie } ...</td>\n",
       "      <td>Au milieu de l’[ interview ], un { incendie } ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un [ incendie ] ...</td>\n",
       "      <td>Au milieu de l’{ interview }, un [ incendie ] ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au milieu de l’[ interview ], un incendie est ...</td>\n",
       "      <td>Au milieu de l’[ interview ], un incendie est ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>GATHERING</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’{ interview }, un incendie est ...</td>\n",
       "      <td>Au milieu de l’{ interview }, un incendie est ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>CBRN_EVENT</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>Le matin du 10 janvier 2010, Arthur et Jacques...</td>\n",
       "      <td>['HAS_CONSEQUENCE']</td>\n",
       "      <td>Au milieu de l’interview, un [ incendie ] est ...</td>\n",
       "      <td>Au milieu de l’interview, un [ incendie ] est ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122039</th>\n",
       "      <td>41884</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122040</th>\n",
       "      <td>41884</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la { porte } du magasin...</td>\n",
       "      <td>Au moment de sortir de la { porte } du magasin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122041</th>\n",
       "      <td>41884</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depuis la { fenêtre } des toilettes, monsieur ...</td>\n",
       "      <td>Depuis la { fenêtre } des toilettes, monsieur ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122042</th>\n",
       "      <td>41884</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>['HAS_COLOR']</td>\n",
       "      <td>Depuis la fenêtre des toilettes, monsieur Bace...</td>\n",
       "      <td>Depuis la fenêtre des toilettes, monsieur Bace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122043</th>\n",
       "      <td>41884</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>MATERIEL</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>Le 14 janvier 2014, en pleine Sibérie, dans un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>Au moment de sortir de la porte du magasin, Mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122044 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_index  e1_id  e2_id     e1_type     e2_type  \\\n",
       "0             2576      1      0        FIRE   GATHERING   \n",
       "1             2576      0      1   GATHERING        FIRE   \n",
       "2             2576      2      0  CBRN_EVENT   GATHERING   \n",
       "3             2576      0      2   GATHERING  CBRN_EVENT   \n",
       "4             2576      2      1  CBRN_EVENT        FIRE   \n",
       "...            ...    ...    ...         ...         ...   \n",
       "122039       41884     11     22    MATERIEL       COLOR   \n",
       "122040       41884     12     22    MATERIEL       COLOR   \n",
       "122041       41884     15     22    MATERIEL       COLOR   \n",
       "122042       41884     17     22    MATERIEL       COLOR   \n",
       "122043       41884     19     22    MATERIEL       COLOR   \n",
       "\n",
       "                                                     text  \\\n",
       "0       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "1       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "2       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "3       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "4       Le matin du 10 janvier 2010, Arthur et Jacques...   \n",
       "...                                                   ...   \n",
       "122039  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122040  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122041  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122042  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "122043  Le 14 janvier 2014, en pleine Sibérie, dans un...   \n",
       "\n",
       "                  relations  \\\n",
       "0                       NaN   \n",
       "1       ['HAS_CONSEQUENCE']   \n",
       "2                       NaN   \n",
       "3       ['HAS_CONSEQUENCE']   \n",
       "4       ['HAS_CONSEQUENCE']   \n",
       "...                     ...   \n",
       "122039                  NaN   \n",
       "122040                  NaN   \n",
       "122041                  NaN   \n",
       "122042        ['HAS_COLOR']   \n",
       "122043                  NaN   \n",
       "\n",
       "                                             reduced_text  \\\n",
       "0       Au milieu de l’[ interview ], un { incendie } ...   \n",
       "1       Au milieu de l’{ interview }, un [ incendie ] ...   \n",
       "2       Au milieu de l’[ interview ], un incendie est ...   \n",
       "3       Au milieu de l’{ interview }, un incendie est ...   \n",
       "4       Au milieu de l’interview, un [ incendie ] est ...   \n",
       "...                                                   ...   \n",
       "122039  Au moment de sortir de la porte du magasin, Mo...   \n",
       "122040  Au moment de sortir de la { porte } du magasin...   \n",
       "122041  Depuis la { fenêtre } des toilettes, monsieur ...   \n",
       "122042  Depuis la fenêtre des toilettes, monsieur Bace...   \n",
       "122043  Au moment de sortir de la porte du magasin, Mo...   \n",
       "\n",
       "                                               input_text  label  \n",
       "0       Au milieu de l’[ interview ], un { incendie } ...      0  \n",
       "1       Au milieu de l’{ interview }, un [ incendie ] ...      1  \n",
       "2       Au milieu de l’[ interview ], un incendie est ...      0  \n",
       "3       Au milieu de l’{ interview }, un incendie est ...      1  \n",
       "4       Au milieu de l’interview, un [ incendie ] est ...      1  \n",
       "...                                                   ...    ...  \n",
       "122039  Au moment de sortir de la porte du magasin, Mo...      0  \n",
       "122040  Au moment de sortir de la { porte } du magasin...      0  \n",
       "122041  Depuis la { fenêtre } des toilettes, monsieur ...      0  \n",
       "122042  Depuis la fenêtre des toilettes, monsieur Bace...      1  \n",
       "122043  Au moment de sortir de la porte du magasin, Mo...      0  \n",
       "\n",
       "[122044 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv(dir_or_file_path: str, index_col=None, sep=',') -> pd.DataFrame:\n",
    "    if os.path.isdir(dir_or_file_path):\n",
    "        all_files = glob.glob(os.path.join(dir_or_file_path , \"*.csv\"))  \n",
    "    else:\n",
    "        assert dir_or_file_path.endswith(\".csv\")\n",
    "        all_files = [dir_or_file_path]\n",
    "    assert len(all_files) > 0\n",
    "    return pd.concat([pd.read_csv(filename, index_col=index_col, header=0, sep=sep) for filename in all_files], axis=0, ignore_index=True)\n",
    "\n",
    "train_df = load_csv(train_dir, index_col=0).assign(**{\n",
    "        # TASK_INPUT_COL: lambda df: df[[\"e1_type\", \"e2_type\", \"reduced_text\"]].apply(lambda row: ' | '.join(row.values.astype(str)), axis=1),\n",
    "        TASK_INPUT_COL: lambda df: df[\"reduced_text\"],\n",
    "        TASK_TARGET_COL: lambda df: 2 + ~pd.isnull(df.relations).astype(int),\n",
    "    },\n",
    ")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(os.path.join(INTERIM_DIR, \"train-entities+reduced_text.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95650</td>\n",
       "      <td>0.783734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26394</td>\n",
       "      <td>0.216266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      95650    0.783734\n",
       "1      26394    0.216266"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97635, 10), (24409, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_RATE = 0.2\n",
    "train_df, val_df = train_test_split(train_df, test_size=VALIDATION_RATE, shuffle=True, random_state=RANDOM_SEED, stratify=train_df[TASK_TARGET_COL])\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76520</td>\n",
       "      <td>0.783735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.216265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      76520    0.783735\n",
       "1      21115    0.216265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19130</td>\n",
       "      <td>0.783727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5279</td>\n",
       "      <td>0.216273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  proportion\n",
       "label                   \n",
       "0      19130    0.783727\n",
       "1       5279    0.216273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(val_df[TASK_TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21115, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_train_df = train_df.query(f\"{TASK_TARGET_COL}==1\")\n",
    "positive_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76520, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_train_df = train_df.query(f\"{TASK_TARGET_COL}==0\")\n",
    "negative_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "# train_df = pd.concat([positive_train_df, negative_train_df.sample(positive_train_df.shape[0])], axis=0)\n",
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagny/.pyenv/versions/3.11.8/envs/kgl11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59, 32062)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "task_special_tokens = [\"<\", \">\", \"{\", \"}\"] + [\n",
    "    f\"{entity_class}\" for entity_class in entity_classes\n",
    "]\n",
    "# add special tokens to the tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(task_special_tokens, special_tokens=True)\n",
    "num_added_tokens, len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 97635\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "task_datasets = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 3653,\n",
       " 'e1_id': 10,\n",
       " 'e2_id': 4,\n",
       " 'e1_type': 'GROUP_OF_INDIVIDUALS',\n",
       " 'e2_type': 'PLACE',\n",
       " 'text': \"Le 13 mars 2020, une guerre civile a éclaté opposant les citoyens de l'[ Est ] de Londres à ceux du Sud. Les citoyens de l'[ Est ] étaient contre l'installation des citoyens du Sud sur leur territoire. Ils ont utilisé du carburant pour brûler des pneus de voiture et étaient armés de bâtons. Cette guerre a blessé au total 25 personnes. Les victimes étaient des { civils } et des employés de PINS, une société de sécurité. Monsieur Kina Evans était parmi les victimes, il a pu être identifié grâce à sa carte d'identité nationale et son téléphone.\",\n",
       " 'relations': None,\n",
       " 'reduced_text': \"Le 13 mars 2020, une guerre civile a éclaté opposant les citoyens de l'[ Est ] de Londres à ceux du Sud. Les citoyens de l'[ Est ] étaient contre l'installation des citoyens du Sud sur leur territoire. Les victimes étaient des { civils } et des employés de PINS, une société de sécurité.\",\n",
       " 'input_text': \"Le 13 mars 2020, une guerre civile a éclaté opposant les citoyens de l'[ Est ] de Londres à ceux du Sud. Les citoyens de l'[ Est ] étaient contre l'installation des citoyens du Sud sur leur territoire. Les victimes étaient des { civils } et des employés de PINS, une société de sécurité.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_index': 51462,\n",
       " 'e1_id': 8,\n",
       " 'e2_id': 11,\n",
       " 'e1_type': 'GROUP_OF_INDIVIDUALS',\n",
       " 'e2_type': 'TIME_EXACT',\n",
       " 'text': '[ Ce matin ], au Luxembourg, une jeune femme nommée Defne Li, présidente de \"l’Ordre des Consommateurs Éclairés\", a effectué un communiqué à la télévision. Depuis de nombreuses années, l’association s’est donné pour mission d\\'informer les consommateurs afin de leur assurer une alimentation de qualité. Un récent rapport de l\\'association a montré que plusieurs marques de glaces et de sorbets de la place étaient contaminées par l\\'oxyde d\\'éthyle, un pesticide hautement cancérigène qui représente donc un danger pour la santé. Defne Li a invité les { personnes } ayant acheté ces aliments contaminés à se rendre dans les supermarchés avec les tickets d\\'achat pour se faire rembourser.',\n",
       " 'relations': None,\n",
       " 'reduced_text': '[ Ce matin ], au Luxembourg, une jeune femme nommée Defne Li, présidente de \"l’Ordre des Consommateurs Éclairés\", a effectué un communiqué à la télévision. Defne Li a invité les { personnes } ayant acheté ces aliments contaminés à se rendre dans les supermarchés avec les tickets d\\'achat pour se faire rembourser.',\n",
       " 'input_text': '[ Ce matin ], au Luxembourg, une jeune femme nommée Defne Li, présidente de \"l’Ordre des Consommateurs Éclairés\", a effectué un communiqué à la télévision. Defne Li a invité les { personnes } ayant acheté ces aliments contaminés à se rendre dans les supermarchés avec les tickets d\\'achat pour se faire rembourser.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f012138d4a9a4d3bad468de85ffd20c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b1773be5304159b2300c7fdf5331bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 97635\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[TASK_INPUT_COL], truncation=True)\n",
    "\n",
    "# We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately\n",
    "# This is way faster\n",
    "# Source https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n",
    "# columns are removed because DataCollatorWithPadding doesn't support any other columns than the ones produced by the tokenizer (or non tensors)\n",
    "tokenized_datasets = task_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_datasets[\"train\"][1]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token numbers distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef04358e5654686a0cff89a4edd35b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b107b6625f4d29999573d9bb3f0dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 97635\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "\n",
    "def count_token_in_dataset_element(example: Dict[str, Any]) -> Dict[str, int]:\n",
    "    return {\"n_tokens\": count_tokens(example[TASK_INPUT_COL])}\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(count_token_in_dataset_element)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 97635/97635 [00:07<00:00, 12589.85it/s]\n",
      "validation: 100%|██████████| 24409/24409 [00:01<00:00, 12445.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97635.000000</td>\n",
       "      <td>24409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.571701</td>\n",
       "      <td>63.273301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.375446</td>\n",
       "      <td>29.174495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train    validation\n",
       "count  97635.000000  24409.000000\n",
       "mean      63.571701     63.273301\n",
       "std       29.375446     29.174495\n",
       "min       10.000000     11.000000\n",
       "25%       43.000000     42.000000\n",
       "50%       58.000000     58.000000\n",
       "75%       78.000000     78.000000\n",
       "max      299.000000    266.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2ntokens_df = pd.DataFrame(\n",
    "    {\n",
    "        split_name: pd.Series(\n",
    "            [e[\"n_tokens\"] for e in tqdm(tokenized_datasets[split_name], split_name)],\n",
    "            name=f\"{split_name}_text_n_tokens\",\n",
    "        )\n",
    "        for split_name in tokenized_datasets.keys()\n",
    "    }\n",
    ")\n",
    "split2ntokens_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split2ntokens_df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e32d648a3b04e56a024344222c4eb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/97635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label', 'input_ids', 'attention_mask', 'n_tokens'],\n",
       "    num_rows: 72\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1245e0cbf2d4d0c972e3d46a6832cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/97635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"De nombreuses < personnes > ont été calcinées au cours de l'incendie.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] == 19)[0]['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 300)[0]['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the batch-level padding with a data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68, 74, 48, 113, 98, 95, 104, 48]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets.remove_columns(task_datasets[\"train\"].column_names)[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items()}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 97635\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text_index', 'e1_id', 'e2_id', 'e1_type', 'e2_type', 'text', 'relations', 'reduced_text', 'input_text', 'label'],\n",
       "        num_rows: 24409\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 113]),\n",
       " 'attention_mask': torch.Size([8, 113]),\n",
       " 'n_tokens': torch.Size([8])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.637970\n",
       "1    2.311982\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = train_df.shape[0]\n",
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "def compute_class_weights(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "    return get_cat_var_distribution(lbl_df[TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "class_weights_df = compute_class_weights(train_df)\n",
    "class_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6379704652378463, 2.311982003315179]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weights_df.values.tolist()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76520</td>\n",
       "      <td>0.783735</td>\n",
       "      <td>0.637970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21115</td>\n",
       "      <td>0.216265</td>\n",
       "      <td>2.311982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  proportion    weight\n",
       "0  76520    0.783735  0.637970\n",
       "1  21115    0.216265  2.311982"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([get_cat_var_distribution(train_df[TASK_TARGET_COL]), class_weights_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32062, 768, padding_idx=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "print(f\"{n_classes=}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32062, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=0)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer and launch the training\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19293' max='244100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 19293/244100 1:29:27 < 17:22:34, 3.59 it/s, Epoch 3.95/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.501993</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.703259</td>\n",
       "      <td>0.771934</td>\n",
       "      <td>0.717036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.444386</td>\n",
       "      <td>0.814044</td>\n",
       "      <td>0.740206</td>\n",
       "      <td>0.801197</td>\n",
       "      <td>0.759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.405684</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.752141</td>\n",
       "      <td>0.827797</td>\n",
       "      <td>0.772701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.380484</td>\n",
       "      <td>0.857307</td>\n",
       "      <td>0.787774</td>\n",
       "      <td>0.836341</td>\n",
       "      <td>0.806736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>0.865787</td>\n",
       "      <td>0.798330</td>\n",
       "      <td>0.841683</td>\n",
       "      <td>0.816021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.374167</td>\n",
       "      <td>0.822320</td>\n",
       "      <td>0.759672</td>\n",
       "      <td>0.846869</td>\n",
       "      <td>0.780308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.354783</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.798146</td>\n",
       "      <td>0.856832</td>\n",
       "      <td>0.819974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>0.341158</td>\n",
       "      <td>0.828998</td>\n",
       "      <td>0.766861</td>\n",
       "      <td>0.856135</td>\n",
       "      <td>0.788405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.337762</td>\n",
       "      <td>0.862674</td>\n",
       "      <td>0.795686</td>\n",
       "      <td>0.859378</td>\n",
       "      <td>0.818469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.332220</td>\n",
       "      <td>0.865541</td>\n",
       "      <td>0.799535</td>\n",
       "      <td>0.867243</td>\n",
       "      <td>0.823257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.325020</td>\n",
       "      <td>0.878733</td>\n",
       "      <td>0.814816</td>\n",
       "      <td>0.867635</td>\n",
       "      <td>0.835672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.331359</td>\n",
       "      <td>0.882666</td>\n",
       "      <td>0.819991</td>\n",
       "      <td>0.867950</td>\n",
       "      <td>0.839533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.340221</td>\n",
       "      <td>0.883690</td>\n",
       "      <td>0.821201</td>\n",
       "      <td>0.871552</td>\n",
       "      <td>0.841494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.308802</td>\n",
       "      <td>0.878365</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.876726</td>\n",
       "      <td>0.837735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.350710</td>\n",
       "      <td>0.892744</td>\n",
       "      <td>0.833454</td>\n",
       "      <td>0.877603</td>\n",
       "      <td>0.852002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.333160</td>\n",
       "      <td>0.872711</td>\n",
       "      <td>0.808412</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.833373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.888443</td>\n",
       "      <td>0.827364</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.847566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.331849</td>\n",
       "      <td>0.884919</td>\n",
       "      <td>0.822519</td>\n",
       "      <td>0.883446</td>\n",
       "      <td>0.845752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.307072</td>\n",
       "      <td>0.892089</td>\n",
       "      <td>0.832060</td>\n",
       "      <td>0.882053</td>\n",
       "      <td>0.852471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-checkpoints\"),\n",
    "    per_device_train_batch_size=20,    \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=50,\n",
    "    eval_strategy=IntervalStrategy.STEPS, # steps\n",
    "    eval_steps = 1000, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    save_steps=1000,\n",
    "    logging_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-tensorboard\"),\n",
    "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model = 'f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"customize the loss to leverage class weights\"\"\"\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # print(labels)\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # print(logits)\n",
    "        # compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping_patience': 4,\n",
       " 'early_stopping_threshold': 0.0,\n",
       " 'early_stopping_patience_counter': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.callback_handler.callbacks[-2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6380, 2.3120], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, access the path of the best checkpoint like this\n",
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "best_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=best_ckpt_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"validation\"].take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(tokenized_datasets[\"validation\"].take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.query(\"e1_type=='ELECTION' & e2_type=='TIME_EXACT'\")[[\"input_text\", \"label\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(train_df.query(\"e1_type=='ELECTION' & e2_type=='TIME_EXACT'\")[\"input_text\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_df.query(\"e1_type=='ELECTION' & e2_type=='TIME_EXACT'\")[\"input_text\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[[\"input_text\", \"label\", \"relations\"]].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"input_text\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.query(\"e1_type=='ELECTION' & e2_type=='TIME_EXACT'\")[[\"input_text\", \"label\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.query(\"e1_type=='ELECTION' & e2_type=='TIME_EXACT'\")[[\"input_text\", \"label\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[68593][[\"input_text\", \"label\", \"relations\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[20455][[\"input_text\", \"label\", \"relations\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[65301][[\"input_text\", \"label\", \"relations\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[67569][[\"input_text\", \"label\", \"relations\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[109413][[\"input_text\", \"label\", \"relations\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"text\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[TASK_TARGET_COL].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['input_ids'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
