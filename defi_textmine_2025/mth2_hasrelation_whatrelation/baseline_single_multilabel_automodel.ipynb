{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sys\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO, \n",
    "     format= '[%(asctime)s|%(levelname)s|%(module)s.py:%(lineno)s] %(message)s',\n",
    "     datefmt='%H:%M:%S'\n",
    " )\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import tqdm\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    ")\n",
    "\n",
    "from defi_textmine_2025.data.utils import TARGET_COL, INTERIM_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:44:50|INFO|1991774308.py:14] mlb.classes_=array(['CREATED', 'DEATHS_NUMBER', 'DIED_IN', 'END_DATE', 'GENDER_FEMALE',\n",
      "       'GENDER_MALE', 'HAS_CATEGORY', 'HAS_COLOR', 'HAS_CONSEQUENCE',\n",
      "       'HAS_CONTROL_OVER', 'HAS_FAMILY_RELATIONSHIP', 'HAS_FOR_HEIGHT',\n",
      "       'HAS_FOR_LENGTH', 'HAS_FOR_WIDTH', 'HAS_LATITUDE', 'HAS_LONGITUDE',\n",
      "       'HAS_QUANTITY', 'INITIATED', 'INJURED_NUMBER', 'IS_AT_ODDS_WITH',\n",
      "       'IS_BORN_IN', 'IS_BORN_ON', 'IS_COOPERATING_WITH', 'IS_DEAD_ON',\n",
      "       'IS_IN_CONTACT_WITH', 'IS_LOCATED_IN', 'IS_OF_NATIONALITY',\n",
      "       'IS_OF_SIZE', 'IS_PART_OF', 'IS_REGISTERED_AS', 'OPERATES_IN',\n",
      "       'RESIDES_IN', 'STARTED_IN', 'START_DATE', 'WAS_CREATED_IN',\n",
      "       'WAS_DISSOLVED_IN', 'WEIGHS'], dtype=object)\n",
      "[22:44:50|INFO|1991774308.py:17] TASK_TARGET_COLS=['CREATED', 'DEATHS_NUMBER', 'DIED_IN', 'END_DATE', 'GENDER_FEMALE', 'GENDER_MALE', 'HAS_CATEGORY', 'HAS_COLOR', 'HAS_CONSEQUENCE', 'HAS_CONTROL_OVER', 'HAS_FAMILY_RELATIONSHIP', 'HAS_FOR_HEIGHT', 'HAS_FOR_LENGTH', 'HAS_FOR_WIDTH', 'HAS_LATITUDE', 'HAS_LONGITUDE', 'HAS_QUANTITY', 'INITIATED', 'INJURED_NUMBER', 'IS_AT_ODDS_WITH', 'IS_BORN_IN', 'IS_BORN_ON', 'IS_COOPERATING_WITH', 'IS_DEAD_ON', 'IS_IN_CONTACT_WITH', 'IS_LOCATED_IN', 'IS_OF_NATIONALITY', 'IS_OF_SIZE', 'IS_PART_OF', 'IS_REGISTERED_AS', 'OPERATES_IN', 'RESIDES_IN', 'STARTED_IN', 'START_DATE', 'WAS_CREATED_IN', 'WAS_DISSOLVED_IN', 'WEIGHS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123  # random reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# BASE_CHECKPOINT = \"bert-base-uncased\"\n",
    "# BASE_CHECKPOINT = \"bert-base-multilingual-cased\"\n",
    "BASE_CHECKPOINT = \"camembert/camembert-base\"\n",
    "TASK_NAME = \"single_multilabel_model\"\n",
    "TASK_INPUT_COL = \"input_text\"\n",
    "\n",
    "entity_classes = {'TERRORIST_OR_CRIMINAL', 'LASTNAME', 'LENGTH', 'NATURAL_CAUSES_DEATH', 'COLOR', 'STRIKE', 'DRUG_OPERATION', 'HEIGHT', 'INTERGOVERNMENTAL_ORGANISATION', 'TRAFFICKING', 'NON_MILITARY_GOVERNMENT_ORGANISATION', 'TIME_MIN', 'DEMONSTRATION', 'TIME_EXACT', 'FIRE', 'QUANTITY_MIN', 'MATERIEL', 'GATHERING', 'PLACE', 'CRIMINAL_ARREST', 'CBRN_EVENT', 'ECONOMICAL_CRISIS', 'ACCIDENT', 'LONGITUDE', 'BOMBING', 'MATERIAL_REFERENCE', 'WIDTH', 'FIRSTNAME', 'MILITARY_ORGANISATION', 'CIVILIAN', 'QUANTITY_MAX', 'CATEGORY', 'POLITICAL_VIOLENCE', 'EPIDEMIC', 'TIME_MAX', 'TIME_FUZZY', 'NATURAL_EVENT', 'SUICIDE', 'CIVIL_WAR_OUTBREAK', 'POLLUTION', 'ILLEGAL_CIVIL_DEMONSTRATION', 'NATIONALITY', 'GROUP_OF_INDIVIDUALS', 'QUANTITY_FUZZY', 'RIOT', 'WEIGHT', 'THEFT', 'MILITARY', 'NON_GOVERNMENTAL_ORGANISATION', 'LATITUDE', 'COUP_D_ETAT', 'ELECTION', 'HOOLIGANISM_TROUBLEMAKING', 'QUANTITY_EXACT', 'AGITATING_TROUBLE_MAKING'}\n",
    "categories_to_check = ['END_DATE', 'GENDER_MALE', 'WEIGHS', 'DIED_IN', 'HAS_FAMILY_RELATIONSHIP', 'IS_DEAD_ON', 'IS_IN_CONTACT_WITH', 'HAS_CATEGORY', 'HAS_CONTROL_OVER', 'IS_BORN_IN', 'IS_OF_SIZE', 'HAS_LATITUDE', 'IS_PART_OF', 'IS_OF_NATIONALITY', 'IS_COOPERATING_WITH', 'DEATHS_NUMBER', 'HAS_FOR_HEIGHT', 'INITIATED', 'WAS_DISSOLVED_IN', 'HAS_COLOR', 'CREATED', 'IS_LOCATED_IN', 'WAS_CREATED_IN', 'IS_AT_ODDS_WITH', 'HAS_CONSEQUENCE', 'HAS_FOR_LENGTH', 'INJURED_NUMBER', 'START_DATE', 'STARTED_IN', 'GENDER_FEMALE', 'HAS_LONGITUDE', 'RESIDES_IN', 'HAS_FOR_WIDTH', 'IS_BORN_ON', 'HAS_QUANTITY', 'OPERATES_IN', 'IS_REGISTERED_AS']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([categories_to_check])\n",
    "logging.info(f\"{mlb.classes_=}\")\n",
    "\n",
    "TASK_TARGET_COLS = mlb.classes_.tolist() # hasrelation?\n",
    "logging.info(f\"{TASK_TARGET_COLS=}\")\n",
    "\n",
    "generated_data_dir_path = os.path.join(INTERIM_DIR, \"reduced_text_w_entity_bracket\")\n",
    "assert os.path.exists(generated_data_dir_path)\n",
    "train_dir = os.path.join(generated_data_dir_path, \"train\")\n",
    "test_dir = os.path.join(generated_data_dir_path, \"test\")\n",
    "\n",
    "preprocessed_data_dir = os.path.join(INTERIM_DIR, \"one_hot_reduced_text_w_entity_bracket\")\n",
    "labeled_preprocessed_data_dir_path = os.path.join(preprocessed_data_dir,\"train\")\n",
    "! mkdir -p {labeled_preprocessed_data_dir_path}\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_var_distribution(cat_var: pd.Series | pd.DataFrame) -> pd.DataFrame:\n",
    "    if isinstance(cat_var, pd.Series):\n",
    "        return pd.concat(\n",
    "            [cat_var.value_counts(), cat_var.value_counts(normalize=True)], axis=1\n",
    "        )\n",
    "    else:\n",
    "        return cat_var.sum(axis=0).sort_values().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets for the binary text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(dir_or_file_path: str, index_col=None, sep=',') -> pd.DataFrame:\n",
    "    if os.path.isdir(dir_or_file_path):\n",
    "        all_files = glob.glob(os.path.join(dir_or_file_path , \"*.csv\"))  \n",
    "    else:\n",
    "        assert dir_or_file_path.endswith(\".csv\")\n",
    "        all_files = [dir_or_file_path]\n",
    "    assert len(all_files) > 0\n",
    "    return pd.concat([pd.read_csv(filename, index_col=index_col, header=0, sep=sep) for filename in all_files], axis=0, ignore_index=True)\n",
    "\n",
    "def format_relations_str_to_list(labels_as_str: str) -> List[str]:\n",
    "    return json.loads(\n",
    "        labels_as_str.replace(\"{\", \"[\").replace(\"}\", \"]\").replace(\"'\", '\"')\n",
    "    )  if not pd.isnull(labels_as_str) else []\n",
    "\n",
    "def process_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.concat([data, pd.DataFrame(mlb.transform(data[TARGET_COL]), columns=mlb.classes_, index=data.index)], axis=1) # .drop([TARGET_COL], axis=1)\n",
    "\n",
    "labeled_df = load_csv(train_dir, index_col=0).assign(**{\n",
    "        TASK_INPUT_COL: lambda df: df[[\"e1_type\", \"e2_type\", \"reduced_text\"]].apply(lambda row: ' | '.join(row.values.astype(str)), axis=1),        \n",
    "    },\n",
    ")\n",
    "labeled_df = process_data(labeled_df.assign(**{TARGET_COL: lambda df: df[TARGET_COL].apply(format_relations_str_to_list)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.to_parquet(os.path.join(INTERIM_DIR, \"train-entities+reduced_text.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAS_LATITUDE</th>\n",
       "      <th>HAS_LONGITUDE</th>\n",
       "      <th>HAS_FOR_HEIGHT</th>\n",
       "      <th>WAS_DISSOLVED_IN</th>\n",
       "      <th>HAS_FOR_WIDTH</th>\n",
       "      <th>WAS_CREATED_IN</th>\n",
       "      <th>HAS_FOR_LENGTH</th>\n",
       "      <th>IS_BORN_ON</th>\n",
       "      <th>IS_REGISTERED_AS</th>\n",
       "      <th>WEIGHS</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_CATEGORY</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>IS_PART_OF</th>\n",
       "      <th>IS_AT_ODDS_WITH</th>\n",
       "      <th>STARTED_IN</th>\n",
       "      <th>OPERATES_IN</th>\n",
       "      <th>IS_IN_CONTACT_WITH</th>\n",
       "      <th>HAS_CONTROL_OVER</th>\n",
       "      <th>IS_LOCATED_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>894</td>\n",
       "      <td>908</td>\n",
       "      <td>1034</td>\n",
       "      <td>1462</td>\n",
       "      <td>1526</td>\n",
       "      <td>1860</td>\n",
       "      <td>2435</td>\n",
       "      <td>2919</td>\n",
       "      <td>4547</td>\n",
       "      <td>9025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAS_LATITUDE  HAS_LONGITUDE  HAS_FOR_HEIGHT  WAS_DISSOLVED_IN  \\\n",
       "0            10             12              12                14   \n",
       "\n",
       "   HAS_FOR_WIDTH  WAS_CREATED_IN  HAS_FOR_LENGTH  IS_BORN_ON  \\\n",
       "0             14              15              16          20   \n",
       "\n",
       "   IS_REGISTERED_AS  WEIGHS  ...  HAS_CATEGORY  GENDER_MALE  START_DATE  \\\n",
       "0                34      41  ...           894          908        1034   \n",
       "\n",
       "   IS_PART_OF  IS_AT_ODDS_WITH  STARTED_IN  OPERATES_IN  IS_IN_CONTACT_WITH  \\\n",
       "0        1462             1526        1860         2435                2919   \n",
       "\n",
       "   HAS_CONTROL_OVER  IS_LOCATED_IN  \n",
       "0              4547           9025  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(labeled_df[TASK_TARGET_COLS])\n",
    "# labeled_df[TASK_TARGET_COLS].sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85430, 46), (36614, 46))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_RATE = 0.3\n",
    "train_df, val_df = train_test_split(labeled_df, test_size=VALIDATION_RATE, shuffle=True, random_state=RANDOM_SEED) #, stratify=train_df[TASK_TARGET_COLS])\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAS_LONGITUDE</th>\n",
       "      <th>HAS_LATITUDE</th>\n",
       "      <th>HAS_FOR_HEIGHT</th>\n",
       "      <th>WAS_DISSOLVED_IN</th>\n",
       "      <th>WAS_CREATED_IN</th>\n",
       "      <th>HAS_FOR_WIDTH</th>\n",
       "      <th>HAS_FOR_LENGTH</th>\n",
       "      <th>IS_BORN_ON</th>\n",
       "      <th>IS_REGISTERED_AS</th>\n",
       "      <th>WEIGHS</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_CATEGORY</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>IS_PART_OF</th>\n",
       "      <th>IS_AT_ODDS_WITH</th>\n",
       "      <th>STARTED_IN</th>\n",
       "      <th>OPERATES_IN</th>\n",
       "      <th>IS_IN_CONTACT_WITH</th>\n",
       "      <th>HAS_CONTROL_OVER</th>\n",
       "      <th>IS_LOCATED_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>733</td>\n",
       "      <td>1022</td>\n",
       "      <td>1076</td>\n",
       "      <td>1340</td>\n",
       "      <td>1747</td>\n",
       "      <td>2052</td>\n",
       "      <td>3166</td>\n",
       "      <td>6316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAS_LONGITUDE  HAS_LATITUDE  HAS_FOR_HEIGHT  WAS_DISSOLVED_IN  \\\n",
       "0              8             8               9                10   \n",
       "\n",
       "   WAS_CREATED_IN  HAS_FOR_WIDTH  HAS_FOR_LENGTH  IS_BORN_ON  \\\n",
       "0              11             11              14          16   \n",
       "\n",
       "   IS_REGISTERED_AS  WEIGHS  ...  HAS_CATEGORY  GENDER_MALE  START_DATE  \\\n",
       "0                19      30  ...           626          647         733   \n",
       "\n",
       "   IS_PART_OF  IS_AT_ODDS_WITH  STARTED_IN  OPERATES_IN  IS_IN_CONTACT_WITH  \\\n",
       "0        1022             1076        1340         1747                2052   \n",
       "\n",
       "   HAS_CONTROL_OVER  IS_LOCATED_IN  \n",
       "0              3166           6316  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(train_df[TASK_TARGET_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAS_LATITUDE</th>\n",
       "      <th>HAS_FOR_LENGTH</th>\n",
       "      <th>HAS_FOR_WIDTH</th>\n",
       "      <th>HAS_FOR_HEIGHT</th>\n",
       "      <th>WAS_CREATED_IN</th>\n",
       "      <th>IS_BORN_ON</th>\n",
       "      <th>WAS_DISSOLVED_IN</th>\n",
       "      <th>HAS_LONGITUDE</th>\n",
       "      <th>WEIGHS</th>\n",
       "      <th>DIED_IN</th>\n",
       "      <th>...</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>HAS_CATEGORY</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>IS_PART_OF</th>\n",
       "      <th>IS_AT_ODDS_WITH</th>\n",
       "      <th>STARTED_IN</th>\n",
       "      <th>OPERATES_IN</th>\n",
       "      <th>IS_IN_CONTACT_WITH</th>\n",
       "      <th>HAS_CONTROL_OVER</th>\n",
       "      <th>IS_LOCATED_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>261</td>\n",
       "      <td>268</td>\n",
       "      <td>301</td>\n",
       "      <td>440</td>\n",
       "      <td>450</td>\n",
       "      <td>520</td>\n",
       "      <td>688</td>\n",
       "      <td>867</td>\n",
       "      <td>1381</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAS_LATITUDE  HAS_FOR_LENGTH  HAS_FOR_WIDTH  HAS_FOR_HEIGHT  \\\n",
       "0             2               2              3               3   \n",
       "\n",
       "   WAS_CREATED_IN  IS_BORN_ON  WAS_DISSOLVED_IN  HAS_LONGITUDE  WEIGHS  \\\n",
       "0               4           4                 4              4      11   \n",
       "\n",
       "   DIED_IN  ...  GENDER_MALE  HAS_CATEGORY  START_DATE  IS_PART_OF  \\\n",
       "0       11  ...          261           268         301         440   \n",
       "\n",
       "   IS_AT_ODDS_WITH  STARTED_IN  OPERATES_IN  IS_IN_CONTACT_WITH  \\\n",
       "0              450         520          688                 867   \n",
       "\n",
       "   HAS_CONTROL_OVER  IS_LOCATED_IN  \n",
       "0              1381           2709  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_var_distribution(val_df[TASK_TARGET_COLS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chances of having a class in the training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAS_LONGITUDE</th>\n",
       "      <th>HAS_LATITUDE</th>\n",
       "      <th>HAS_FOR_HEIGHT</th>\n",
       "      <th>WAS_DISSOLVED_IN</th>\n",
       "      <th>WAS_CREATED_IN</th>\n",
       "      <th>HAS_FOR_WIDTH</th>\n",
       "      <th>HAS_FOR_LENGTH</th>\n",
       "      <th>IS_BORN_ON</th>\n",
       "      <th>IS_REGISTERED_AS</th>\n",
       "      <th>WEIGHS</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_CATEGORY</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>IS_PART_OF</th>\n",
       "      <th>IS_AT_ODDS_WITH</th>\n",
       "      <th>STARTED_IN</th>\n",
       "      <th>OPERATES_IN</th>\n",
       "      <th>IS_IN_CONTACT_WITH</th>\n",
       "      <th>HAS_CONTROL_OVER</th>\n",
       "      <th>IS_LOCATED_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>733</td>\n",
       "      <td>1022</td>\n",
       "      <td>1076</td>\n",
       "      <td>1340</td>\n",
       "      <td>1747</td>\n",
       "      <td>2052</td>\n",
       "      <td>3166</td>\n",
       "      <td>6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>261</td>\n",
       "      <td>301</td>\n",
       "      <td>440</td>\n",
       "      <td>450</td>\n",
       "      <td>520</td>\n",
       "      <td>688</td>\n",
       "      <td>867</td>\n",
       "      <td>1381</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HAS_LONGITUDE  HAS_LATITUDE  HAS_FOR_HEIGHT  WAS_DISSOLVED_IN  \\\n",
       "train              8             8               9                10   \n",
       "val                4             2               3                 4   \n",
       "\n",
       "       WAS_CREATED_IN  HAS_FOR_WIDTH  HAS_FOR_LENGTH  IS_BORN_ON  \\\n",
       "train              11             11              14          16   \n",
       "val                 4              3               2           4   \n",
       "\n",
       "       IS_REGISTERED_AS  WEIGHS  ...  HAS_CATEGORY  GENDER_MALE  START_DATE  \\\n",
       "train                19      30  ...           626          647         733   \n",
       "val                  15      11  ...           268          261         301   \n",
       "\n",
       "       IS_PART_OF  IS_AT_ODDS_WITH  STARTED_IN  OPERATES_IN  \\\n",
       "train        1022             1076        1340         1747   \n",
       "val           440              450         520          688   \n",
       "\n",
       "       IS_IN_CONTACT_WITH  HAS_CONTROL_OVER  IS_LOCATED_IN  \n",
       "train                2052              3166           6316  \n",
       "val                   867              1381           2709  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_category_sizes_df = pd.concat([get_cat_var_distribution(df[TASK_TARGET_COLS]).T[0].rename(name) for df, name in zip([train_df, val_df], [\"train\", \"val\"])], axis=1)\n",
    "train_val_category_sizes_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85430"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAS_LONGITUDE</th>\n",
       "      <th>HAS_LATITUDE</th>\n",
       "      <th>HAS_FOR_HEIGHT</th>\n",
       "      <th>WAS_DISSOLVED_IN</th>\n",
       "      <th>WAS_CREATED_IN</th>\n",
       "      <th>HAS_FOR_WIDTH</th>\n",
       "      <th>HAS_FOR_LENGTH</th>\n",
       "      <th>IS_BORN_ON</th>\n",
       "      <th>IS_REGISTERED_AS</th>\n",
       "      <th>WEIGHS</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_CATEGORY</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>IS_PART_OF</th>\n",
       "      <th>IS_AT_ODDS_WITH</th>\n",
       "      <th>STARTED_IN</th>\n",
       "      <th>OPERATES_IN</th>\n",
       "      <th>IS_IN_CONTACT_WITH</th>\n",
       "      <th>HAS_CONTROL_OVER</th>\n",
       "      <th>IS_LOCATED_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>1022.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1747.000000</td>\n",
       "      <td>2052.000000</td>\n",
       "      <td>3166.000000</td>\n",
       "      <td>6316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>688.000000</td>\n",
       "      <td>867.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>2709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proba_to_be_in_batch</th>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>0.066617</td>\n",
       "      <td>0.091795</td>\n",
       "      <td>0.096433</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.176763</td>\n",
       "      <td>0.260753</td>\n",
       "      <td>0.459081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      HAS_LONGITUDE  HAS_LATITUDE  HAS_FOR_HEIGHT  \\\n",
       "train                      8.000000      8.000000        9.000000   \n",
       "val                        4.000000      2.000000        3.000000   \n",
       "proba_to_be_in_batch       0.000749      0.000749        0.000843   \n",
       "\n",
       "                      WAS_DISSOLVED_IN  WAS_CREATED_IN  HAS_FOR_WIDTH  \\\n",
       "train                        10.000000        11.00000       11.00000   \n",
       "val                           4.000000         4.00000        3.00000   \n",
       "proba_to_be_in_batch          0.000936         0.00103        0.00103   \n",
       "\n",
       "                      HAS_FOR_LENGTH  IS_BORN_ON  IS_REGISTERED_AS     WEIGHS  \\\n",
       "train                       14.00000   16.000000         19.000000  30.000000   \n",
       "val                          2.00000    4.000000         15.000000  11.000000   \n",
       "proba_to_be_in_batch         0.00131    0.001497          0.001778   0.002806   \n",
       "\n",
       "                      ...  HAS_CATEGORY  GENDER_MALE  START_DATE   IS_PART_OF  \\\n",
       "train                 ...    626.000000   647.000000  733.000000  1022.000000   \n",
       "val                   ...    268.000000   261.000000  301.000000   440.000000   \n",
       "proba_to_be_in_batch  ...      0.057142     0.059008    0.066617     0.091795   \n",
       "\n",
       "                      IS_AT_ODDS_WITH   STARTED_IN  OPERATES_IN  \\\n",
       "train                     1076.000000  1340.000000  1747.000000   \n",
       "val                        450.000000   520.000000   688.000000   \n",
       "proba_to_be_in_batch         0.096433     0.118811     0.152359   \n",
       "\n",
       "                      IS_IN_CONTACT_WITH  HAS_CONTROL_OVER  IS_LOCATED_IN  \n",
       "train                        2052.000000       3166.000000    6316.000000  \n",
       "val                           867.000000       1381.000000    2709.000000  \n",
       "proba_to_be_in_batch            0.176763          0.260753       0.459081  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "# train_val_category_sizes_df.assign(in_batch_proba = train_category_sizes.map(lambda category_size: 1 - ((train_df.shape[0] - category_size) / train_df.shape[0])**BATCH_SIZE))\n",
    "train_val_category_sizes_df = train_val_category_sizes_df.assign(proba_to_be_in_batch = train_val_category_sizes_df.train.map(lambda categ_size: 1 - np.prod([(train_df.shape[0] - categ_size - i) / (train_df.shape[0] - i) for i in range(BATCH_SIZE)])))\n",
    "train_val_category_sizes_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# undersampling negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66864"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out_scope = train_df[TASK_TARGET_COLS].sum(axis=1).rename(\"n_labels\").to_frame().query(\"n_labels==0\").shape[0]\n",
    "n_out_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18566"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in_scope = train_df[TASK_TARGET_COLS].sum(axis=1).rename(\"n_labels\").to_frame().query(\"n_labels>0\").shape[0]\n",
    "n_in_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27766810241684614"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in_scope / n_out_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenized datasets for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CHECKPOINT)\n",
    "task_special_tokens = [\"<\", \">\", \"{\", \"}\"] + [\n",
    "    f\"{entity_class}\" for entity_class in entity_classes\n",
    "]\n",
    "# add special tokens to the tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(task_special_tokens, special_tokens=True)\n",
    "num_added_tokens, len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init the train-valid datasets from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "task_datasets = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example: dict):\n",
    "    return tokenizer(example[TASK_INPUT_COL], truncation=True)\n",
    "\n",
    "# We’re using batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately\n",
    "# This is way faster\n",
    "# Source https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n",
    "# columns are removed because DataCollatorWithPadding doesn't support any other columns than the ones produced by the tokenizer (or non tensors)\n",
    "tokenized_datasets = task_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenized_datasets[\"train\"][1]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token numbers distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer(text)[\"input_ids\"])\n",
    "\n",
    "\n",
    "def count_token_in_dataset_element(example: Dict[str, Any]) -> Dict[str, int]:\n",
    "    return {\"n_tokens\": count_tokens(example[TASK_INPUT_COL])}\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(count_token_in_dataset_element)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split2ntokens_df = pd.DataFrame(\n",
    "    {\n",
    "        split_name: pd.Series(\n",
    "            [e[\"n_tokens\"] for e in tqdm(tokenized_datasets[split_name], split_name)],\n",
    "            name=f\"{split_name}_text_n_tokens\",\n",
    "        )\n",
    "        for split_name in tokenized_datasets.keys()\n",
    "    }\n",
    ")\n",
    "split2ntokens_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split2ntokens_df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] == 19)[0]['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets[\"train\"].filter(lambda x: x['n_tokens'] > 300)[0]['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the batch-level padding with a data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tokenized_datasets.remove_columns(task_datasets[\"train\"].column_names)[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items()}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weight of classes to handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "n_examples = train_df.shape[0]\n",
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "def compute_class_weights(lbl_df: pd.DataFrame) -> pd.Series:\n",
    "    return get_cat_var_distribution(lbl_df[TASK_TARGET_COL]).reset_index(drop=False)[\"count\"].apply(lambda x: (1 / x) * (n_examples / n_classes)).rename(\"weight\")\n",
    "pd.concat([get_cat_var_distribution(train_df[TASK_TARGET_COL]), compute_class_weights(train_df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train_df[TASK_TARGET_COL].nunique()\n",
    "print(f\"{n_classes=}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_CHECKPOINT, num_labels=n_classes)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the trainer\n",
    "\n",
    "Source: https://stackoverflow.com/questions/69087044/early-stopping-in-bert-trainer-instances#69087153\n",
    "\n",
    "1. Use `load_best_model_at_end = True` (EarlyStoppingCallback() requires this to be True).\n",
    "2. `evaluation_strategy = 'steps'` or IntervalStrategy.STEPS instead of 'epoch'.\n",
    "3. `eval_steps = 50` (evaluate the metrics after N steps).\n",
    "4. `metric_for_best_model = 'f1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-checkpoints\"),\n",
    "    per_device_train_batch_size=16,    \n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS, # steps\n",
    "    eval_steps = 1000, # Evaluation and Save happens every 50 steps\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    save_steps=1000,\n",
    "    logging_dir=os.path.join(MODELS_DIR, f\"{TASK_NAME}-byTrainerAPI-tensorboard\"),\n",
    "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model = 'f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.callback_handler.callbacks[-2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, access the path of the best checkpoint like this\n",
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "best_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=best_ckpt_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"input_text\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.iloc[:10][[\"input_text\", \"label\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(val_ds[\"text\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[TASK_TARGET_COL].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[\"input_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['input_ids'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(samples['input_ids'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
